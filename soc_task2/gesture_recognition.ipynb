{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gesture recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCrVZWQ8mWfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import numpy as np\n",
        "import copy\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yOav9UtFhqXK",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = 200, 200\n",
        "#number of output classes\n",
        "nb_classes = 5\n",
        "# Number of epochs to train \n",
        "nb_epoch = 15  #25\n",
        "# Total number of convolutional filters to use\n",
        "nb_filters = 32\n",
        "# Max pooling\n",
        "nb_pool = 2\n",
        "# Size of convolution kernel\n",
        "nb_conv = 3\n",
        "#batch size in training the model\n",
        "batch_size = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtqQgfGMmWgE",
        "colab_type": "text"
      },
      "source": [
        "# **CNN model pytorch version**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HD96FiF6ydMn",
        "colab": {}
      },
      "source": [
        "# #pytorch version of keras CNN model  .\n",
        "#do not run this\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(nb_conv, nb_conv))\n",
        "        self.conv2 = nn.Conv2d(32, 32 , kernel_size=(nb_conv, nb_conv))\n",
        "\n",
        "        self.drop1 = nn.Dropout(0.5)\n",
        "        self.drop2 = nn.Dropout(0.5)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.dense1 = nn.Linear(32*98*98, 128)  # equivalent to Dense in keras\n",
        "        self.dense2 = nn.Linear(128, 5)  # equivalent to Dense in keras\n",
        "        self.softmax = nn.LogSoftmax(dim=1)    \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.drop1(x)\n",
        "        x = x.view(-1, 32*98*98)\n",
        "        x = self.dense1(x)\n",
        "        x = self.drop2(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ly8s6fVodItL",
        "outputId": "4f7498ce-8793-490e-ff31-e169a118a875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "input_shape=(1, 200, 200)\n",
        "model = NeuralNet()\n",
        "summary(model, input_shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 198, 198]             320\n",
            "            Conv2d-2         [-1, 32, 196, 196]           9,248\n",
            "         MaxPool2d-3           [-1, 32, 98, 98]               0\n",
            "           Dropout-4           [-1, 32, 98, 98]               0\n",
            "            Linear-5                  [-1, 128]      39,338,112\n",
            "           Dropout-6                  [-1, 128]               0\n",
            "            Linear-7                    [-1, 5]             645\n",
            "================================================================\n",
            "Total params: 39,348,325\n",
            "Trainable params: 39,348,325\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.15\n",
            "Forward/backward pass size (MB): 23.64\n",
            "Params size (MB): 150.10\n",
            "Estimated Total Size (MB): 173.90\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAvS_WCKmWgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#Over here we want to only update the parameters of the classifier so\n",
        "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.0003)\n",
        "torch.optim.Adagrad(params, lr=0.001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5hqAKqomWg7",
        "colab_type": "text"
      },
      "source": [
        "# **Defining the train/test loader with it's transforms**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oX9QPVrmWg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_dir = r'C:/Users/Meeta Malviya/Videos/data2/train'\n",
        "test_dir = r'C:/Users/Meeta Malviya/Videos/data2/test'\n",
        "\n",
        "train_transforms = transforms.Compose([transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "                                      transforms.RandomRotation(degrees=10),\n",
        "                                      transforms.ColorJitter(),\n",
        "                                      transforms.Grayscale(num_output_channels=3),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.CenterCrop(size=224),  # Image net standards\n",
        "                                      transforms.ToTensor()\n",
        "                                      ])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.Grayscale(num_output_channels=3),\n",
        "                                      transforms.ToTensor()\n",
        "                                     ])\n",
        "\n",
        "validation_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                            transforms.CenterCrop(224),\n",
        "                                            transforms.Grayscale(num_output_channels=3),\n",
        "                                            transforms.ToTensor()\n",
        "                                           ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDCK8hyzmWhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading in the dataset\n",
        "\n",
        "train_data = datasets.ImageFolder(img_dir, transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(test_dir, transform=test_transforms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfqePed6mWhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# obtain training indices that will be used for validation\n",
        "valid_size = 0.2\n",
        "\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "# load training data in batches\n",
        "train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                           batch_size=batch_size,\n",
        "                                           sampler=train_sampler,\n",
        "                                           num_workers=0)\n",
        "\n",
        "# load validation data in batches\n",
        "valid_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                           batch_size=batch_size,\n",
        "                                           sampler=valid_sampler,\n",
        "                                           num_workers=0)\n",
        "\n",
        "# load test data in batches\n",
        "test_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                          batch_size=batch_size,\n",
        "                                          num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2aFikj0mWhh",
        "colab_type": "text"
      },
      "source": [
        "## **Loading the Resnet-50 model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFFBhnpgmWhk",
        "colab_type": "code",
        "colab": {},
        "outputId": "6992f1eb-4bdd-4f50-d59d-e6367d9c68e8"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#pretrained=True will download a pretrained network for us\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "#Freezing model parameters and defining the fully connected network to be attached to the model, loss function and the optimizer.\n",
        "#then we add a sequential model and loss criterion and optimizer\n",
        "for param in model.parameters():\n",
        "    param.require_grad = False\n",
        " \n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 5),\n",
        "    nn.LogSoftmax(dim=1)    \n",
        ")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adagrad(model.parameters(), lr=0.001, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=5, bias=True)\n",
              "    (1): LogSoftmax()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwbYZVR5mWiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining check point for the model and saving weights of the best \n",
        "def save_checkpoint(state, is_best, filename=r'C:/Users/Meeta Malviya/Videos/Vgg/restnet-vedio'):\n",
        "    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n",
        "\n",
        "    if is_best:\n",
        "        print (\"=> Saving a new best\")\n",
        "        torch.save(state, filename)  # save checkpoint\n",
        "    else:\n",
        "        print (\"=> Validation Accuracy did not improve\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6CZWbWlmWiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#definig early stopping class\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVNIU5bvn5Gy",
        "colab_type": "text"
      },
      "source": [
        "# **Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQw8uyAJmWiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, n_epochs):\n",
        "    \n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "    \n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=40, verbose=1)\n",
        "    \n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # prep model for training\n",
        "        for batch, (data, target) in enumerate(train_loader, 1):\n",
        "            # clear the gradients of all optimized variables\n",
        "            optimizer.zero_grad()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the loss\n",
        "            loss = criterion(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval() # prep model for evaluation\n",
        "        for data, target in valid_loader:\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the loss\n",
        "            loss = criterion(output, target)\n",
        "            # record validation loss\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(n_epochs))\n",
        "        \n",
        "        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
        "                     f'train_loss: {train_loss:.5f} ' +\n",
        "                     f'valid_loss: {valid_loss:.5f}')\n",
        "        \n",
        "        print(print_msg)\n",
        "        \n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "        # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return  model, avg_train_losses, avg_valid_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKhFMMvVmWi6",
        "colab_type": "code",
        "colab": {},
        "outputId": "5530ea60-4474-407a-df6a-98392f35f0c1"
      },
      "source": [
        "# batch_size = 50\n",
        "n_epochs = 35\n",
        "\n",
        "# train_loader, test_loader, valid_loader = create_datasets(batch_size)\n",
        "\n",
        "# early stopping patience; how long to wait after last time validation loss improved.\n",
        "patience = 10\n",
        "\n",
        "model, train_loss, valid_loss = train_model(model, n_epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1/35] train_loss: 1.19047 valid_loss: 1.32220\n",
            "Validation loss decreased (inf --> 1.322195).  Saving model ...\n",
            "[ 2/35] train_loss: 0.48581 valid_loss: 1.21489\n",
            "Validation loss decreased (1.322195 --> 1.214891).  Saving model ...\n",
            "[ 3/35] train_loss: 0.18483 valid_loss: 1.35713\n",
            "EarlyStopping counter: 1 out of 40\n",
            "[ 4/35] train_loss: 0.12383 valid_loss: 0.34189\n",
            "Validation loss decreased (1.214891 --> 0.341893).  Saving model ...\n",
            "[ 5/35] train_loss: 0.07302 valid_loss: 0.29995\n",
            "Validation loss decreased (0.341893 --> 0.299948).  Saving model ...\n",
            "[ 6/35] train_loss: 0.06208 valid_loss: 0.52369\n",
            "EarlyStopping counter: 1 out of 40\n",
            "[ 7/35] train_loss: 0.03999 valid_loss: 0.59391\n",
            "EarlyStopping counter: 2 out of 40\n",
            "[ 8/35] train_loss: 0.03044 valid_loss: 0.09090\n",
            "Validation loss decreased (0.299948 --> 0.090902).  Saving model ...\n",
            "[ 9/35] train_loss: 0.01568 valid_loss: 0.11672\n",
            "EarlyStopping counter: 1 out of 40\n",
            "[10/35] train_loss: 0.02005 valid_loss: 0.23502\n",
            "EarlyStopping counter: 2 out of 40\n",
            "[11/35] train_loss: 0.01546 valid_loss: 0.11099\n",
            "EarlyStopping counter: 3 out of 40\n",
            "[12/35] train_loss: 0.01241 valid_loss: 0.10003\n",
            "EarlyStopping counter: 4 out of 40\n",
            "[13/35] train_loss: 0.00901 valid_loss: 0.10035\n",
            "EarlyStopping counter: 5 out of 40\n",
            "[14/35] train_loss: 0.01194 valid_loss: 0.40290\n",
            "EarlyStopping counter: 6 out of 40\n",
            "[15/35] train_loss: 0.01653 valid_loss: 0.09870\n",
            "EarlyStopping counter: 7 out of 40\n",
            "[16/35] train_loss: 0.00649 valid_loss: 0.07201\n",
            "Validation loss decreased (0.090902 --> 0.072006).  Saving model ...\n",
            "[17/35] train_loss: 0.00418 valid_loss: 0.08159\n",
            "EarlyStopping counter: 1 out of 40\n",
            "[18/35] train_loss: 0.01094 valid_loss: 0.31233\n",
            "EarlyStopping counter: 2 out of 40\n",
            "[19/35] train_loss: 0.01655 valid_loss: 0.11822\n",
            "EarlyStopping counter: 3 out of 40\n",
            "[20/35] train_loss: 0.00662 valid_loss: 0.27479\n",
            "EarlyStopping counter: 4 out of 40\n",
            "[21/35] train_loss: 0.00407 valid_loss: 0.16802\n",
            "EarlyStopping counter: 5 out of 40\n",
            "[22/35] train_loss: 0.00449 valid_loss: 0.07783\n",
            "EarlyStopping counter: 6 out of 40\n",
            "[23/35] train_loss: 0.00288 valid_loss: 0.08121\n",
            "EarlyStopping counter: 7 out of 40\n",
            "[24/35] train_loss: 0.00330 valid_loss: 0.10968\n",
            "EarlyStopping counter: 8 out of 40\n",
            "[25/35] train_loss: 0.00248 valid_loss: 0.10219\n",
            "EarlyStopping counter: 9 out of 40\n",
            "[26/35] train_loss: 0.00389 valid_loss: 0.05267\n",
            "Validation loss decreased (0.072006 --> 0.052672).  Saving model ...\n",
            "[27/35] train_loss: 0.00344 valid_loss: 0.09603\n",
            "EarlyStopping counter: 1 out of 40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-14-2908a309f1b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpatience\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-13-78c17aa687ee>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, n_epochs)\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m# backward pass: compute gradient of the loss with respect to model parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[1;31m# perform a single optimization step (parameter update)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu3LltMtmWjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saving the model\n",
        "PATH=r'C:/Users/Meeta Malviya/Videos/Vgg/resnet_weights'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4CsNYAVmWjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH=r'C:/Users/Meeta Malviya/Videos/Vgg/restnet_weights'\n",
        "\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9_emBOUoOZI",
        "colab_type": "text"
      },
      "source": [
        "#**Testing the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HnPhyXxmWjY",
        "colab_type": "code",
        "colab": {},
        "outputId": "3b5ffe6b-146a-41ab-93f2-17a729693afc"
      },
      "source": [
        "def test(model, criterion):\n",
        "# monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "    i = 0\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        # move to GPU\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "        print(\"batch:\", i, \"/ 5\")\n",
        "        i = i + 1\n",
        "            \n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (100. * correct / total, correct, total))\n",
        "test(model_test, criterion)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch: 0 / 5\n",
            "batch: 1 / 5\n",
            "batch: 2 / 5\n",
            "batch: 3 / 5\n",
            "Test Loss: 0.110705\n",
            "\n",
            "\n",
            "Test Accuracy: 95% (191/200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XdVnOG_osx3",
        "colab_type": "text"
      },
      "source": [
        "# Defining functions for real time prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-WkZpI1mWmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_process(image):\n",
        "    predict_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.Grayscale(num_output_channels=3),\n",
        "                                      transforms.ToTensor()\n",
        "                                            ])\n",
        "    image = predict_transforms(image)\n",
        "    return image \n",
        "\n",
        "\n",
        "def predict(img, model):\n",
        "    \n",
        "    img = Image.fromarray(img)\n",
        "    img = image_process(img)\n",
        "\n",
        "    img = np.expand_dims(img, 0)\n",
        "    img = torch.from_numpy(img)\n",
        "    \n",
        "    model.eval()\n",
        "    target = model(img)\n",
        "    \n",
        "    out = F.softmax(target,dim=1)\n",
        "    topk = out.cpu().topk(5)\n",
        "    \n",
        "    return (e.data.numpy().squeeze().tolist() for e in topk)\n",
        "\n",
        "\n",
        "def plotting(img, prob, classes, class_names):\n",
        "    \n",
        "    fig,ax = plt.subplots()\n",
        "    y_pos = np.arange(len(probs))\n",
        "    plt.bar(y_pos,probs)\n",
        "    ax.set_xticks(y_pos)\n",
        "    ax.set_xticklabels(classs)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(True, which='both')\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC9a41HSmWmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#capturing vedio\n",
        "cap = cv2.VideoCapture(0)\n",
        "cv2.namedWindow('Original', cv2.WINDOW_NORMAL)\n",
        "frame = 0\n",
        "\n",
        "#a rectangle will be displayed gesture ought to me created there\n",
        "while(cap.isOpened()):\n",
        "    ret, img = cap.read()\n",
        "    cv2.rectangle(img,(300,300),(100,100),(0,255,0),0)\n",
        "    cv2.imshow('frame',img)\n",
        "    crop_img = img[100:300, 100:300]\n",
        "    cv2.imshow('cropped image',crop_img)   \n",
        "\n",
        "    while( frame % 100 == 1 ):\n",
        "    #so that the we don't feed in random transition image \n",
        "        prob, classes = predict(crop_img, model.to(device))\n",
        "        class_names = [test_loader.dataset.classes[e] for e in classes]\n",
        "        \n",
        "        print(prob)\n",
        "        print(class_names)\n",
        "        plotting(prob,class_names)\n",
        "        print(frame)\n",
        "        frame = frame+1\n",
        "\n",
        "    if frame == 45:\n",
        "        plt.close('all')\n",
        "           \n",
        "    k = cv2.waitKey(100)\n",
        "    frame = frame+1\n",
        "    if k & 0xFF == ord('q'):\n",
        "            break "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfKbEbAMmWmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}